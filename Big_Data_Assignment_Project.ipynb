{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055b08b3-d407-4f6c-8f89-1c83a7c21719",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession;\n",
    "from pyspark.context import SparkContext;\n",
    "\n",
    "# warehouse_location points to the default location for managed databases and tables\n",
    "from os.path import abspath\n",
    "warehouse_location = abspath('spark-warehouse')\n",
    "\n",
    "spark = SparkSession \\\n",
    "    . builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"ISM6562 PySpark Tutorials\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", warehouse_location) \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc =spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\") # only display errors (not warnings)\n",
    "\n",
    "# note: If you have multiple spark sessions running (like from a previous notebook you've run), \n",
    "# this spark session webUI will be on a different port than the default (4040). One way to \n",
    "# identify this part is with the following line. If there was only one spark session running, \n",
    "# this will be 4040. If it's higher, it means there are still other spark sesssions still running.\n",
    "spark_session_port = spark.sparkContext.uiWebUrl.split(\":\")[-1]\n",
    "print(\"Spark Session WebUI Port: \" + spark_session_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d49a5f-df12-4723-89dd-b597cf3d7c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968c5808-c568-49ee-aa6a-5c9361b44802",
   "metadata": {},
   "source": [
    "### Let's create a pandas dataframe and import it into PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a87815d7-1f9a-4aee-9229-47cdc1a4000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94784fe2-75cb-42a5-a762-4b444bfde32d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
       "3  7795-CFOCW    Male              0      No         No      45           No   \n",
       "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
       "0  No phone service             DSL             No  ...               No   \n",
       "1                No             DSL            Yes  ...              Yes   \n",
       "2                No             DSL            Yes  ...               No   \n",
       "3  No phone service             DSL            Yes  ...              Yes   \n",
       "4                No     Fiber optic             No  ...               No   \n",
       "\n",
       "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
       "0          No          No              No  Month-to-month              Yes   \n",
       "1          No          No              No        One year               No   \n",
       "2          No          No              No  Month-to-month              Yes   \n",
       "3         Yes          No              No        One year               No   \n",
       "4          No          No              No  Month-to-month              Yes   \n",
       "\n",
       "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
       "0           Electronic check          29.85         29.85    No  \n",
       "1               Mailed check          56.95        1889.5    No  \n",
       "2               Mailed check          53.85        108.15   Yes  \n",
       "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
       "4           Electronic check          70.70        151.65   Yes  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a5e30d-32d7-47de-9d18-7584190ba051",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = spark.createDataFrame(df)\n",
    "\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0589e0da-3d85-4e42-8828-2a99bb29bca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640c9322-9eda-4a74-97cc-abba9fb98722",
   "metadata": {},
   "source": [
    "###  Export a PySpark dataframe into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf307c89-be7f-4d29-b7a3-597db47fe651",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df_spark.toPandas()\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437864bf-54c6-4e41-b2f8-a1a7e13d910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e300353-d850-491c-8729-c92eaf92c977",
   "metadata": {},
   "source": [
    "### List the Database and tables in it in the Spark Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd6718c-89d4-4236-b21d-c8dffe17104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.listTables()  # If no database is specified, the current database and catalog are used. This API includes all temporary views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a35335-4242-4e97-bd17-6cd5515f26ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=spark.sql(\"show databases\")\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567a0b5f-74ae-4e28-b4a5-162417b60344",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables=spark.sql(\"show tables\")\n",
    "tables.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d475063b-ac49-4381-83eb-83bb7fbb8a76",
   "metadata": {},
   "source": [
    "### Load the dataset into the spark datawarehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44fba8e-439c-4aa3-81b7-1c37e2e7ea98",
   "metadata": {},
   "source": [
    " We will use the spark dataframe API to load the data. We will then use the spark sql API to create a table from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48c51c5-c222-47ee-8937-093b168fd997",
   "metadata": {},
   "outputs": [],
   "source": [
    "telcochurn = spark.read.csv('data/telcochurn.csv', header=True, inferSchema=True);\n",
    "\n",
    "# display the first 5 rows of the dataframe\n",
    "telcochurn.show(5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f90e0bd-dfa4-4447-b175-88a1f8f75bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "telcochurn.createOrReplaceTempView(\"telcochurn_tmp_view\")  # create a tempview table for the telco data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9bd8f2-59ba-4460-8cb0-b8aa7e308c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"SELECT * FROM telcochurn_tmp_view\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23d1c39-68b0-46b7-ae00-6e1b31dc7ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f50f703-cefa-4ac9-a4cc-05c93254435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"SELECT * FROM telcochurn_tmp_view\") # note that this will generate an error\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97b2bc1-7291-49c2-8b97-358af29e0235",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(telcochurn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1339dda9-dc9b-4372-9b64-f7db97a9cd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS w10_db;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cc790d-03c4-45e4-855d-695468fff142",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#boston.writeTo('boston')\n",
    "\n",
    "telcochurn.write.mode(\"overwrite\").saveAsTable(\"w10_db.telcochurn\")\n",
    "\n",
    "#boston.write.mode(\"overwrite\").saveAsTable(\"boston\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef94ef8e-9d4e-4a13-8dde-a03b7dd1b4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.listTables('w10_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1a2d21-8b21-4b51-b100-ec6f59e785b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"SELECT * FROM w10_db.telcochurn\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00b97da-ff10-4323-a75c-a78cb505fa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, we will keep the table and access it in another notebook. Therefore, this line is commented out\n",
    "#spark.sql(\"DROP TABLE telcochurn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39329a4f-7550-47a9-8a9b-0b4f4f99b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbc8d26-b7fd-4a57-be7b-5bfd7a3c807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.listTables('w10_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010f2e73-972d-448b-a004-5705ddadb394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2961ed8a-1d8d-4283-b633-0252ddae9a22",
   "metadata": {},
   "source": [
    "### Working with Pyspark magic SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aea648-1e39-4e82-8d75-7707e6ee1a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType\n",
    "# see here for more info on the schema: https://spark.apache.org/docs/latest/sql-programming-guide.html#inferring-the-schema-using-reflection\n",
    "# and here https://sparkbyexamples.com/pyspark/pyspark-sql-types-datatype-with-examples/\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"movieid\", IntegerType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"date\", StringType(), True),\n",
    "    StructField(\"unkown\", StringType(), True),\n",
    "    StructField(\"url\", StringType(), True),\n",
    "    ])\n",
    "\n",
    "churn = spark.read.csv('data/telcochurn.csv', header=False, schema=schema,  sep = '|')\n",
    "\n",
    "# display the first 5 rows of the dataframe\n",
    "churn.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3756161c-9fc2-49b6-adb0-5f5821f744e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn.createOrReplaceTempView(\"movies_tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5383edb7-d656-45cf-bf82-9364d4c3e10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sparksql_magic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e66849-264d-4433-b4c1-db64ee2289b7",
   "metadata": {},
   "source": [
    "# Change the code from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191367ed-1625-4ace-a35c-788c3c557156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstration, note that when using sparksql, we can save the results in a temporary view\n",
    "# but this (and other sparksql switches) will not work with VSCode. It will work in Jupyter Notebook.\n",
    "# %%sparksql --view tempdf\n",
    "# select * from movies_tmp limit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9670f061-7274-414d-b114-b74e235a41cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use sparksql to show current tables, but this will only work in Jupyter Notebook. It will \n",
    "# not work in VSCode.\n",
    "#%%sparksql \n",
    "#SHOW TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b815b18-6370-4b33-af16-51f0b49e391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark.sql(\"\"\"SELECT\n",
    "  movieid,\n",
    "  title\n",
    "FROM movies_tmp\"\"\"\n",
    ")\n",
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af01ff8-d33c-4206-89d3-268cac990671",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df.write.saveAsTable(\"movies\", mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c18639-34b9-499f-89de-491743e95bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType\n",
    "# see here for more info on the schema: https://spark.apache.org/docs/latest/sql-programming-guide.html#inferring-the-schema-using-reflection\n",
    "# and here https://sparkbyexamples.com/pyspark/pyspark-sql-types-datatype-with-examples/\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"userid\", IntegerType(), True),\n",
    "    StructField(\"movieid\", IntegerType(), True),\n",
    "    StructField(\"rating\", IntegerType(), True),\n",
    "    StructField(\"timestamp\", StringType(), True),\n",
    "    ])\n",
    "\n",
    "movierating = spark.read.csv('data/u.data', header=False, schema=schema,  sep = '\\t')\n",
    "\n",
    "# display the first 5 rows of the dataframe\n",
    "movierating.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ad8665-87cd-4a51-b4c0-b487d72639bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "movierating.write.saveAsTable(\"movieratings\", mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c903da44-0d86-47a1-a0a5-7b4014db9d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sparksql\n",
    "select * from movieratings limit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eba973c-e708-4e09-9fdb-d4561ae4ab7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRating = spark.table('movieratings')\n",
    "dfMovies = spark.table('movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045ae36a-4d38-4c7f-a540-3a90f40f32f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for more on colaborative filtering, see here https://spark.apache.org/docs/2.2.0/ml-collaborative-filtering.html\n",
    "# \n",
    "from pyspark.ml.recommendation import ALS\n",
    " \n",
    "#split training and testing\n",
    "(dftraining, dftest) = dfRating.randomSplit([0.8, 0.2])\n",
    " \n",
    "## Build the recommendation model using ALS on the training data\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"userid\", \n",
    "    itemCol=\"movieid\", ratingCol=\"rating\",\n",
    "    coldStartStrategy=\"drop\")\n",
    "model = als.fit(dftraining)\n",
    " \n",
    "#display predicted rating\n",
    "predictions = model.transform(dftest)\n",
    "predictions.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5564fca-2607-4388-8022-5fe453408a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
